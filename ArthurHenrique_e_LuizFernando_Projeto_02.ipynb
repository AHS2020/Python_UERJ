{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArthurHenrique_e_LuizFernando_Projeto_02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKDTe2CkJgkbXTnYPTkjGF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AHS2020/Python_UERJ/blob/master/ArthurHenrique_e_LuizFernando_Projeto_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94iO6WxBMIBR"
      },
      "source": [
        "## PROJETO\n",
        "\n",
        "Questão 1 - Criar uma `Classe` Perceptron em Python. Vocês podem seguir o esqueleto de Classe apresentado abaixo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QqR3SlOMccC"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "class MyPerceptron():\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
        "        '''\n",
        "        método de inicialização que tem os seguintes atributos:\n",
        "        no_of_inputs: número de features passadas como input ao perceptron\n",
        "        threshold: número de iterações de atualização do peso\n",
        "        learning_rate: taxa com a qual os pesos são atualizados a cada iteração\n",
        "        weights: inicialização dos pesos (dica: pode inicializar com método np.zeros). Não se esquecer que o vetor dos pesos\n",
        "        terá no_of_inputs + 1 elementos por conta do bias que é o primeiro elemento.\n",
        "        '''\n",
        "        self.b = 0\n",
        "        self.weights = np.zeros(no_of_inputs)              \n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "      '''\n",
        "      método de implementação da função de ativação.\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\n",
        "      '''         \n",
        "      f = np.heaviside(np.dot(self.weights, inputs) + self.b, 0)\n",
        "      return f\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "      '''\n",
        "      método de treino. É aqui que os pesos são atualizados um certo número de vezes (determinado pelo valor do threshold).\n",
        "      Nesse método é feita a comparação entre o resultado da função de ativação (predição) e\n",
        "      o resultado esperado (label).\n",
        "      O método deve atualizar tanto os pesos quanto o bias (lembre que o bias é o primeiro valor do vetor peso e tem input 1.)\n",
        "      A atualização é feita iterativamente um número (threshold) de vezes.\n",
        "      '''\n",
        "      for i in range(self.threshold):\n",
        "          for j in range(len(training_inputs)):\n",
        "            prediction = self.predict(training_inputs[j])\n",
        "            error = labels[j] - prediction\n",
        "            self.weights += self.learning_rate * error * training_inputs[j]\n",
        "            self.b += self.learning_rate * error * 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIzbCIgDMtpm",
        "outputId": "0872f431-7fbd-45a3-bcc8-44a779931499"
      },
      "source": [
        "print(iris.target_names)    # target = label\n",
        "print(iris.feature_names)   # features = características\n",
        "# Pelo primeiro print acima, as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWmcAEBESr-h"
      },
      "source": [
        "> Pelo primeiro print acima diz que os targets são: 0: Setosa, 1: Versicolor e 2: Virginica.\n",
        "\n",
        "> Já o segundo print diz que as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PrFG4NxML4K"
      },
      "source": [
        "Questão 2 - Aplique essa classe nos dados das flores Iris para determinar se uma Íris com um certo comprimento e largura de **pétala** e **sépala**  é uma Íris Setosa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i-ms-sCL2uh"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Percep = MyPerceptron(4)\n",
        "\n",
        "X = iris.data[:, (0,1,2,3)]               # inputs\n",
        "y = (iris.target == 0).astype(int)        # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim   \n",
        "\n",
        "# Separação da amostra das Iris em duas: uma para treino e outra para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)\n",
        "\n",
        "#print(X_train)\n",
        "#print(\" \")\n",
        "#print(X_test)\n",
        "#print(\" \")\n",
        "#print(y_train)\n",
        "#print(\" \")\n",
        "#print(y_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyOSfnopQ3ln",
        "outputId": "5726048b-86e7-44e2-9cb3-95b1101b1aae"
      },
      "source": [
        "Treino = Percep.train(X_train,y_train)\n",
        "Predição = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  Pred = Percep.predict(X_test[i])\n",
        "  Predição.append(int(Pred))\n",
        "\n",
        "a = Predição\n",
        "b = ''.join(str(a).split(','))\n",
        "\n",
        "print(b)\n",
        "print(\" \")\n",
        "print(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGt4Bf0YZmj0"
      },
      "source": [
        "> Utilizando o MyPerceptron, o resultado obtido foi que a lista de predição tem os mesmos dados da lista de teste (y_test).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbeB9sgeMNh4"
      },
      "source": [
        "Questão 3 - Compare o resultado da sua classe com a classe Peceptron do módulo do scikit-learn `linear_model`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuhmQpO3adKA",
        "outputId": "833d9ba6-2ae6-4ec1-c80f-8eb0233a8644"
      },
      "source": [
        "#A partir do módulo do scikit-learn linear_model.\n",
        "Percep_sl = Perceptron()                  \n",
        "Treino_2 = Percep_sl.fit(X_train,y_train)\n",
        "Predição_2 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  Pred = Percep_sl.predict([X_test[i]])\n",
        "  Predição_2.append(int(Pred))\n",
        "\n",
        "a_2 = Predição_2\n",
        "b_2 = ''.join(str(a_2).split(','))\n",
        "\n",
        "print(b_2)\n",
        "print(\" \")\n",
        "print(y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zthCKRULbK0D"
      },
      "source": [
        "> Utilizando o Peceptron do módulo do scikit-learn `linear_model`, o resultado obtido foi que a lista de predição tem os mesmos dados da lista de teste (y_test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHHWj7ZJa8iz",
        "outputId": "7c165ce9-0198-4865-b9f5-a567291c7fc0"
      },
      "source": [
        "print(b)\n",
        "print(\" \")\n",
        "print(b_2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBvquOoIbzm_"
      },
      "source": [
        "> Os resultados obtidos com MyPerceptron e os obtidos com Peceptron do módulo do scikit-learn `linear_model` são exatamente os mesmos resultados para esses dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_oXNnGKMPcE"
      },
      "source": [
        "Questão 4 - Você pode pensar em algum outro exemplo em que possa aplicar o modelo do Perceptron? Quando esse modelo falha?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ibHNi9cb90"
      },
      "source": [
        "> Podemos aplicar o modelo do Perceptron para todo sistema binário, ou seja com duas opções de resposta.\n",
        "\n",
        "> Esse método pode falhar quando se testa os limites de seu aprendizado. Se chegarmos com dados além dos limites que ela aprendeu é possível achar uma falha por exemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGyIwiLMbi7U"
      },
      "source": [
        "> Encontrando os limites dos dados do nosso experimento.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsPT_h7PeJXf",
        "outputId": "59b6daed-f138-4a5e-cab3-d10f5936d14a"
      },
      "source": [
        "for i in range(150): #Setosa\n",
        "  if i < 50:\n",
        "    print(X[i])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.1 3.5 1.4 0.2]\n",
            "[4.9 3.  1.4 0.2]\n",
            "[4.7 3.2 1.3 0.2]\n",
            "[4.6 3.1 1.5 0.2]\n",
            "[5.  3.6 1.4 0.2]\n",
            "[5.4 3.9 1.7 0.4]\n",
            "[4.6 3.4 1.4 0.3]\n",
            "[5.  3.4 1.5 0.2]\n",
            "[4.4 2.9 1.4 0.2]\n",
            "[4.9 3.1 1.5 0.1]\n",
            "[5.4 3.7 1.5 0.2]\n",
            "[4.8 3.4 1.6 0.2]\n",
            "[4.8 3.  1.4 0.1]\n",
            "[4.3 3.  1.1 0.1]\n",
            "[5.8 4.  1.2 0.2]\n",
            "[5.7 4.4 1.5 0.4]\n",
            "[5.4 3.9 1.3 0.4]\n",
            "[5.1 3.5 1.4 0.3]\n",
            "[5.7 3.8 1.7 0.3]\n",
            "[5.1 3.8 1.5 0.3]\n",
            "[5.4 3.4 1.7 0.2]\n",
            "[5.1 3.7 1.5 0.4]\n",
            "[4.6 3.6 1.  0.2]\n",
            "[5.1 3.3 1.7 0.5]\n",
            "[4.8 3.4 1.9 0.2]\n",
            "[5.  3.  1.6 0.2]\n",
            "[5.  3.4 1.6 0.4]\n",
            "[5.2 3.5 1.5 0.2]\n",
            "[5.2 3.4 1.4 0.2]\n",
            "[4.7 3.2 1.6 0.2]\n",
            "[4.8 3.1 1.6 0.2]\n",
            "[5.4 3.4 1.5 0.4]\n",
            "[5.2 4.1 1.5 0.1]\n",
            "[5.5 4.2 1.4 0.2]\n",
            "[4.9 3.1 1.5 0.2]\n",
            "[5.  3.2 1.2 0.2]\n",
            "[5.5 3.5 1.3 0.2]\n",
            "[4.9 3.6 1.4 0.1]\n",
            "[4.4 3.  1.3 0.2]\n",
            "[5.1 3.4 1.5 0.2]\n",
            "[5.  3.5 1.3 0.3]\n",
            "[4.5 2.3 1.3 0.3]\n",
            "[4.4 3.2 1.3 0.2]\n",
            "[5.  3.5 1.6 0.6]\n",
            "[5.1 3.8 1.9 0.4]\n",
            "[4.8 3.  1.4 0.3]\n",
            "[5.1 3.8 1.6 0.2]\n",
            "[4.6 3.2 1.4 0.2]\n",
            "[5.3 3.7 1.5 0.2]\n",
            "[5.  3.3 1.4 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJvb9WiiPPv"
      },
      "source": [
        "#Setosa\n",
        "> Mínimos de 1.0 e 0.1 para petal length e petal width respectivamente.\n",
        "\n",
        "> Máximos de 1.9 e 0.6 para petal length e petal width respectivamente.\n",
        "\n",
        "> Mínimos de 4.3 e 2.3 para sepal length e sepal width respectivamente.\n",
        "\n",
        "> Máximos de 5.8 e 4.4 para sepal length e sepal width respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_d5IZ40hnWi",
        "outputId": "6f8907ec-a96f-4206-aae7-c7d18bbc0f53"
      },
      "source": [
        "for i in range(150): #Versicolor\n",
        "  if i > 49 and i < 100:\n",
        "    print(X[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.  3.2 4.7 1.4]\n",
            "[6.4 3.2 4.5 1.5]\n",
            "[6.9 3.1 4.9 1.5]\n",
            "[5.5 2.3 4.  1.3]\n",
            "[6.5 2.8 4.6 1.5]\n",
            "[5.7 2.8 4.5 1.3]\n",
            "[6.3 3.3 4.7 1.6]\n",
            "[4.9 2.4 3.3 1. ]\n",
            "[6.6 2.9 4.6 1.3]\n",
            "[5.2 2.7 3.9 1.4]\n",
            "[5.  2.  3.5 1. ]\n",
            "[5.9 3.  4.2 1.5]\n",
            "[6.  2.2 4.  1. ]\n",
            "[6.1 2.9 4.7 1.4]\n",
            "[5.6 2.9 3.6 1.3]\n",
            "[6.7 3.1 4.4 1.4]\n",
            "[5.6 3.  4.5 1.5]\n",
            "[5.8 2.7 4.1 1. ]\n",
            "[6.2 2.2 4.5 1.5]\n",
            "[5.6 2.5 3.9 1.1]\n",
            "[5.9 3.2 4.8 1.8]\n",
            "[6.1 2.8 4.  1.3]\n",
            "[6.3 2.5 4.9 1.5]\n",
            "[6.1 2.8 4.7 1.2]\n",
            "[6.4 2.9 4.3 1.3]\n",
            "[6.6 3.  4.4 1.4]\n",
            "[6.8 2.8 4.8 1.4]\n",
            "[6.7 3.  5.  1.7]\n",
            "[6.  2.9 4.5 1.5]\n",
            "[5.7 2.6 3.5 1. ]\n",
            "[5.5 2.4 3.8 1.1]\n",
            "[5.5 2.4 3.7 1. ]\n",
            "[5.8 2.7 3.9 1.2]\n",
            "[6.  2.7 5.1 1.6]\n",
            "[5.4 3.  4.5 1.5]\n",
            "[6.  3.4 4.5 1.6]\n",
            "[6.7 3.1 4.7 1.5]\n",
            "[6.3 2.3 4.4 1.3]\n",
            "[5.6 3.  4.1 1.3]\n",
            "[5.5 2.5 4.  1.3]\n",
            "[5.5 2.6 4.4 1.2]\n",
            "[6.1 3.  4.6 1.4]\n",
            "[5.8 2.6 4.  1.2]\n",
            "[5.  2.3 3.3 1. ]\n",
            "[5.6 2.7 4.2 1.3]\n",
            "[5.7 3.  4.2 1.2]\n",
            "[5.7 2.9 4.2 1.3]\n",
            "[6.2 2.9 4.3 1.3]\n",
            "[5.1 2.5 3.  1.1]\n",
            "[5.7 2.8 4.1 1.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGyPwDKQX06r"
      },
      "source": [
        "#Versicolor\n",
        "\n",
        "> Mínimos de 3.0 e 1.0 para petal length e petal width respectivamente.\n",
        "\n",
        "> Máximos de 5.1 e 1.8 para petal length e petal width respectivamente.\n",
        "\n",
        "> Mínimos de 4.9 e 2.0 para sepal length e sepal width respectivamente.\n",
        "\n",
        "> Máximos de 7.0 e 3.4 para sepal length e sepal width respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB9RheDzW0DD",
        "outputId": "f800f859-06af-4962-8519-53550908fbb3"
      },
      "source": [
        "for i in range(150): #Virginica\n",
        "  if i > 99:\n",
        "    print(X[i])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.3 3.3 6.  2.5]\n",
            "[5.8 2.7 5.1 1.9]\n",
            "[7.1 3.  5.9 2.1]\n",
            "[6.3 2.9 5.6 1.8]\n",
            "[6.5 3.  5.8 2.2]\n",
            "[7.6 3.  6.6 2.1]\n",
            "[4.9 2.5 4.5 1.7]\n",
            "[7.3 2.9 6.3 1.8]\n",
            "[6.7 2.5 5.8 1.8]\n",
            "[7.2 3.6 6.1 2.5]\n",
            "[6.5 3.2 5.1 2. ]\n",
            "[6.4 2.7 5.3 1.9]\n",
            "[6.8 3.  5.5 2.1]\n",
            "[5.7 2.5 5.  2. ]\n",
            "[5.8 2.8 5.1 2.4]\n",
            "[6.4 3.2 5.3 2.3]\n",
            "[6.5 3.  5.5 1.8]\n",
            "[7.7 3.8 6.7 2.2]\n",
            "[7.7 2.6 6.9 2.3]\n",
            "[6.  2.2 5.  1.5]\n",
            "[6.9 3.2 5.7 2.3]\n",
            "[5.6 2.8 4.9 2. ]\n",
            "[7.7 2.8 6.7 2. ]\n",
            "[6.3 2.7 4.9 1.8]\n",
            "[6.7 3.3 5.7 2.1]\n",
            "[7.2 3.2 6.  1.8]\n",
            "[6.2 2.8 4.8 1.8]\n",
            "[6.1 3.  4.9 1.8]\n",
            "[6.4 2.8 5.6 2.1]\n",
            "[7.2 3.  5.8 1.6]\n",
            "[7.4 2.8 6.1 1.9]\n",
            "[7.9 3.8 6.4 2. ]\n",
            "[6.4 2.8 5.6 2.2]\n",
            "[6.3 2.8 5.1 1.5]\n",
            "[6.1 2.6 5.6 1.4]\n",
            "[7.7 3.  6.1 2.3]\n",
            "[6.3 3.4 5.6 2.4]\n",
            "[6.4 3.1 5.5 1.8]\n",
            "[6.  3.  4.8 1.8]\n",
            "[6.9 3.1 5.4 2.1]\n",
            "[6.7 3.1 5.6 2.4]\n",
            "[6.9 3.1 5.1 2.3]\n",
            "[5.8 2.7 5.1 1.9]\n",
            "[6.8 3.2 5.9 2.3]\n",
            "[6.7 3.3 5.7 2.5]\n",
            "[6.7 3.  5.2 2.3]\n",
            "[6.3 2.5 5.  1.9]\n",
            "[6.5 3.  5.2 2. ]\n",
            "[6.2 3.4 5.4 2.3]\n",
            "[5.9 3.  5.1 1.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-pSu3DsaGI7"
      },
      "source": [
        "#Virginica\n",
        "\n",
        "> Mínimos de 4.5 e 1.4 para petal length e petal width respectivamente.\n",
        "\n",
        "> Máximos de 6.9 e 2.5 para petal length e petal width respectivamente.\n",
        "\n",
        "> Mínimos de 4.9 e 2.2 para sepal length e sepal width respectivamente.\n",
        "\n",
        "> Máximos de 7.9 e 3.8 para sepal length e sepal width respectivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XlpRb9TbH4-"
      },
      "source": [
        "> No experimento buscamos a Íris Setosa, então trabalharemos em torno de seus limites.\n",
        "\n",
        "> Observando os dados é possível perceber que as larguras e os compimentos de sepalas dos três tipos de Íris se misturam, logo serão utilizados os máximos desses valores para a Íris Setosa, assim só levaremos em conta os dados das pétalas.\n",
        "\n",
        "> Já as larguras e comprimentos de pétalas da Íris setosa se distaca dos outros tipos de Íris. Então para buscar falhas, precisamos trabalhar nos limites dos dados de largura e comprimento para as pétalas de Íris Setosa.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv7obtDKbINP",
        "outputId": "aad937e2-4c8a-4986-cc39-bdadcb4b0c74"
      },
      "source": [
        "Pred_0 = Percep.predict([5.8,4.4,1.0,0.1])\n",
        "print(Pred_0)\n",
        "Pred_1 = Percep.predict([5.8,4.4,0,0])\n",
        "print(Pred_1)\n",
        "Pred_2 = Percep.predict([1000,1000,0,0])\n",
        "print(Pred_2)\n",
        "Pred_3 = Percep.predict([1000,1000,1.0,0.1])\n",
        "print(Pred_3)\n",
        "Pred_4 = Percep.predict([0,0,0,0])\n",
        "print(Pred_4)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPzHUuJlbOCt"
      },
      "source": [
        "> Testando o mínimo dos dados de Setosa, pode-se ver que o peceptron reconhece que, Íris com qualquer tamanho de sepala ou até sem sepalas e pétalas pequenas de mais ou até sem pétalas são todas Íris Setosas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpD3PACkfCZV"
      },
      "source": [
        "#Setosa\n",
        "\n",
        "> Máximos de 1.9 e 0.6 para petal length e petal width respectivamente.\n",
        "\n",
        "#Versicolor\n",
        "\n",
        "> Mínimos de 3.0 e 1.0 para petal length e petal width respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1QJWC8tfMOH",
        "outputId": "4df6e589-c002-4fb3-9a8a-f7415484ffcb"
      },
      "source": [
        "Pred_01 = Percep.predict([5.8,4.4,1.9,0.6])\n",
        "print(Pred_01)\n",
        "Pred_02 = Percep.predict([5.8,4.4,2.0,0.7])\n",
        "print(Pred_02)\n",
        "\n",
        "print(' ')\n",
        "\n",
        "Pred_03 = Percep.predict([5.8,4.4,3.0,1.0])\n",
        "print(Pred_03)\n",
        "Pred_04 = Percep.predict([5.8,4.4,3.0,0.6])\n",
        "print(Pred_02)\n",
        "Pred_05 = Percep.predict([5.8,4.4,3.1,0.6])\n",
        "print(Pred_05)\n",
        "Pred_06 = Percep.predict([5.8,4.4,3.0,0.7])\n",
        "print(Pred_06)\n",
        "\n",
        "print(' ')\n",
        "\n",
        "Pred_07 = Percep.predict([5.8,4.4,3.0,1.0])\n",
        "print(Pred_07)\n",
        "Pred_08 = Percep.predict([5.8,4.4,1.9,1.0])\n",
        "print(Pred_08)\n",
        "Pred_09 = Percep.predict([5.8,4.4,1.9,3.0])\n",
        "print(Pred_09)\n",
        "Pred_10 = Percep.predict([5.8,4.4,2.0,3.0])\n",
        "print(Pred_10)\n",
        "Pred_11 = Percep.predict([5.8,4.4,2.0,1.0])\n",
        "print(Pred_11)\n",
        "Pred_11 = Percep.predict([5.8,4.4,2.8,1.0])\n",
        "print(Pred_11)\n",
        "Pred_11 = Percep.predict([5.8,4.4,2.8,1.1])\n",
        "print(Pred_11)\n",
        "Pred_11 = Percep.predict([5.8,4.4,2.8,1.2])\n",
        "print(Pred_11)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            " \n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            " \n",
            "0.0\n",
            "1.0\n",
            "1.0\n",
            "0.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSVXegMhbSH1"
      },
      "source": [
        "> Testando os limites entre os máximos dos dados das pétalas de Íris Setosa e os mínimo dos dados das pétalas de Íris Versicolor, pode-se ver que o peceptron reconhece que pétalas muito grandes para serem Setosas ou seja muito perto dos limites das petalas de íris Versicolos também são consideradas Setosas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnHSj8Njls4F",
        "outputId": "9f3992b1-f016-4267-9d80-4f9295760f1e"
      },
      "source": [
        "Pred_12 = Percep.predict([1000,1000,1.9,0.6])\n",
        "print(Pred_12)\n",
        "Pred_13 = Percep.predict([1000,1000,2.0,0.7])\n",
        "print(Pred_13)\n",
        "\n",
        "print(' ')\n",
        "\n",
        "Pred_14 = Percep.predict([1000,1000,3.0,1.0])\n",
        "print(Pred_14)\n",
        "Pred_15 = Percep.predict([1000,1000,3.0,0.6])\n",
        "print(Pred_15)\n",
        "Pred_16 = Percep.predict([1000,1000,3.1,0.6])\n",
        "print(Pred_16)\n",
        "Pred_17 = Percep.predict([1000,1000,3.0,0.7])\n",
        "print(Pred_17)\n",
        "\n",
        "print(' ')\n",
        "\n",
        "Pred_18 = Percep.predict([1000,1000,3.0,1.0])\n",
        "print(Pred_18)\n",
        "Pred_19 = Percep.predict([1000,1000,1.9,1.0])\n",
        "print(Pred_19)\n",
        "Pred_20 = Percep.predict([1000,1000,1.9,3.0])\n",
        "print(Pred_20)\n",
        "Pred_21 = Percep.predict([1000,1000,2.0,3.0])\n",
        "print(Pred_21)\n",
        "Pred_22 = Percep.predict([1000,1000,2.0,1.0])\n",
        "print(Pred_22)\n",
        "Pred_23 = Percep.predict([1000,1000,2.8,1.0])\n",
        "print(Pred_23)\n",
        "Pred_24 = Percep.predict([1000,1000,2.8,1.1])\n",
        "print(Pred_24)\n",
        "Pred_25 = Percep.predict([1000,1000,2.8,1.2])\n",
        "print(Pred_25)\n",
        "\n",
        "print(' ')\n",
        "\n",
        "Pred_26 = Percep.predict([2000,2000,1000,500])\n",
        "print(Pred_26)\n",
        "Pred_27 = Percep.predict([0,4000,2000,1000])\n",
        "print(Pred_27)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            " \n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            " \n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            " \n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBCIiRxEnOce"
      },
      "source": [
        "> Além disso, quando se extrapola os dados de sepalas os limites para se considerar uma Íris como Setosa ficam muito grandes, como se pode ver em Pred_26. Mas como vemos em Pred_27 só é necessário extrapolar os dados de comprimento de sepalas."
      ]
    }
  ]
}