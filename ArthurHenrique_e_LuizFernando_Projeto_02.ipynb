{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArthurHenrique_e_LuizFernando_Projeto_02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpZsVwegKUyCMPcflH0Q+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AHS2020/Python_UERJ/blob/master/ArthurHenrique_e_LuizFernando_Projeto_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94iO6WxBMIBR"
      },
      "source": [
        "## PROJETO\n",
        "\n",
        "1. Criar uma `Classe` Perceptron em Python. Vocês podem seguir o esqueleto de Classe apresentado abaixo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QqR3SlOMccC"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "class MyPerceptron():\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
        "        '''\n",
        "        método de inicialização que tem os seguintes atributos:\n",
        "        no_of_inputs: número de features passadas como input ao perceptron\n",
        "        threshold: número de iterações de atualização do peso\n",
        "        learning_rate: taxa com a qual os pesos são atualizados a cada iteração\n",
        "        weights: inicialização dos pesos (dica: pode inicializar com método np.zeros). Não se esquecer que o vetor dos pesos\n",
        "        terá no_of_inputs + 1 elementos por conta do bias que é o primeiro elemento.\n",
        "        '''\n",
        "        self.b = 0\n",
        "        self.weights = np.zeros(no_of_inputs)              \n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "      '''\n",
        "      método de implementação da função de ativação.\n",
        "      inputs: array com o conjunto de inputs (features). No projeto pedimos que considerassem o comprimento e largura da pétala da Iris.\n",
        "      Não se esquecer que o produto da função de ativação é um produto escalar e pode ser calculado pelo método np.dot\n",
        "      '''         \n",
        "      f = np.heaviside(np.dot(self.weights, inputs) + self.b, 0)\n",
        "      return f\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "      '''\n",
        "      método de treino. É aqui que os pesos são atualizados um certo número de vezes (determinado pelo valor do threshold).\n",
        "      Nesse método é feita a comparação entre o resultado da função de ativação (predição) e\n",
        "      o resultado esperado (label).\n",
        "      O método deve atualizar tanto os pesos quanto o bias (lembre que o bias é o primeiro valor do vetor peso e tem input 1.)\n",
        "      A atualização é feita iterativamente um número (threshold) de vezes.\n",
        "      '''\n",
        "      for i in range(self.threshold):\n",
        "          for j in range(len(training_inputs)):\n",
        "            prediction = self.predict(training_inputs[j])\n",
        "            error = labels[j] - prediction\n",
        "            self.weights += self.learning_rate * error * training_inputs[j]\n",
        "            self.b += self.learning_rate * error * 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIzbCIgDMtpm",
        "outputId": "0293a2d4-d8e2-4b8a-83e9-51580864b52e"
      },
      "source": [
        "print(iris.target_names)    # target = label\n",
        "print(iris.feature_names)   # features = características\n",
        "# Pelo primeiro print acima, as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWmcAEBESr-h"
      },
      "source": [
        "> Pelo primeiro print acima diz que os targets são: 0: Setosa, 1: Versicolor e 2: Virginica.\n",
        "\n",
        "> Já o segundo print diz que as features são: 0: sepal length, 1: sepal width, 2: petal length, 3: petal width.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PrFG4NxML4K"
      },
      "source": [
        "2. Aplique essa classe nos dados das flores Iris para determinar se uma Iris com um certo comprimento e largura da **pétala** é uma Iris Setosa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i-ms-sCL2uh"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Percep = MyPerceptron(2)\n",
        "\n",
        "# Vamos selecionar somente as features petal length e petal width:\n",
        "X = iris.data[:, (2,3)]               # inputs\n",
        "y = (iris.target == 0).astype(int)    # label = iris setosa. Retorna uma lista com os labels da Iris-Setosa. 0: não, 1: sim   \n",
        "\n",
        "# Separação da amostra das Iris em duas: uma para treino e outra para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)\n",
        "\n",
        "#print(X_train)\n",
        "#print(\" \")\n",
        "#print(X_test)\n",
        "#print(\" \")\n",
        "#print(y_train)\n",
        "#print(\" \")\n",
        "#print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyOSfnopQ3ln",
        "outputId": "2cf071f8-e3a2-442c-9eb5-2604b03a15d7"
      },
      "source": [
        "Treino = Percep.train(X_train,y_train)\n",
        "Predição = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  Pred = Percep.predict(X_test[i])\n",
        "  Predição.append(int(Pred))\n",
        "\n",
        "a = Predição\n",
        "b = ''.join(str(a).split(','))\n",
        "\n",
        "print(b)\n",
        "print(\" \")\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGt4Bf0YZmj0"
      },
      "source": [
        "> Utilizando o MyPerceptron, o resultado obtido foi que a lista de predição tem os mesmos dados da lista de teste (y_test).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbeB9sgeMNh4"
      },
      "source": [
        "3. Compare o resultado da sua classe com a classe Peceptron do módulo do scikit-learn `linear_model`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuhmQpO3adKA",
        "outputId": "08b878c0-4ae1-495c-81a6-1a37f96bbbd7"
      },
      "source": [
        "#A partir do módulo do scikit-learn linear_model.\n",
        "Percep_sl = Perceptron()                  # dois inputs: comprimento e largura da pétala\n",
        "Treino_2 = Percep_sl.fit(X_train,y_train) # Train\n",
        "Predição_2 = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  Pred = Percep_sl.predict([X_test[i]])\n",
        "  Predição_2.append(int(Pred))\n",
        "\n",
        "a_2 = Predição_2\n",
        "b_2 = ''.join(str(a_2).split(','))\n",
        "\n",
        "print(b_2)\n",
        "print(\" \")\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
            " 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0\n",
            " 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zthCKRULbK0D"
      },
      "source": [
        "> Utilizando o Peceptron do módulo do scikit-learn `linear_model`, o resultado obtido foi que a lista de predição tem os mesmos dados da lista de teste (y_test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHHWj7ZJa8iz",
        "outputId": "7e79c570-70bb-483a-c97a-564c3e02db64"
      },
      "source": [
        "print(b)\n",
        "print(\" \")\n",
        "print(b_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n",
            " \n",
            "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBvquOoIbzm_"
      },
      "source": [
        "> Os resultados obtidos com MyPerceptron e os obtidos com Peceptron do módulo do scikit-learn `linear_model` são exatamente os mesmos resultados para esses dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_oXNnGKMPcE"
      },
      "source": [
        "4. Você pode pensar em algum outro exemplo em que possa aplicar o modelo do Perceptron? Quando esse modelo falha?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ibHNi9cb90"
      },
      "source": [
        "> Podemos aplicar o modelo do Perceptron para todo sistema binário, ou seja com duas opções de resposta.\n",
        "\n",
        "> Esse método pode falhar quando se testa os limites de seu aprendizado. Se chegarmos com dados além dos limites que ela aprendeu é possível achar uma falha por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsPT_h7PeJXf",
        "outputId": "4c3db2ee-b934-4917-8da6-0f5eb677d3c2"
      },
      "source": [
        "for i in range(150): #Setosa\n",
        "  if i < 50:\n",
        "    print(X[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.4 0.2]\n",
            "[1.4 0.2]\n",
            "[1.3 0.2]\n",
            "[1.5 0.2]\n",
            "[1.4 0.2]\n",
            "[1.7 0.4]\n",
            "[1.4 0.3]\n",
            "[1.5 0.2]\n",
            "[1.4 0.2]\n",
            "[1.5 0.1]\n",
            "[1.5 0.2]\n",
            "[1.6 0.2]\n",
            "[1.4 0.1]\n",
            "[1.1 0.1]\n",
            "[1.2 0.2]\n",
            "[1.5 0.4]\n",
            "[1.3 0.4]\n",
            "[1.4 0.3]\n",
            "[1.7 0.3]\n",
            "[1.5 0.3]\n",
            "[1.7 0.2]\n",
            "[1.5 0.4]\n",
            "[1.  0.2]\n",
            "[1.7 0.5]\n",
            "[1.9 0.2]\n",
            "[1.6 0.2]\n",
            "[1.6 0.4]\n",
            "[1.5 0.2]\n",
            "[1.4 0.2]\n",
            "[1.6 0.2]\n",
            "[1.6 0.2]\n",
            "[1.5 0.4]\n",
            "[1.5 0.1]\n",
            "[1.4 0.2]\n",
            "[1.5 0.2]\n",
            "[1.2 0.2]\n",
            "[1.3 0.2]\n",
            "[1.4 0.1]\n",
            "[1.3 0.2]\n",
            "[1.5 0.2]\n",
            "[1.3 0.3]\n",
            "[1.3 0.3]\n",
            "[1.3 0.2]\n",
            "[1.6 0.6]\n",
            "[1.9 0.4]\n",
            "[1.4 0.3]\n",
            "[1.6 0.2]\n",
            "[1.4 0.2]\n",
            "[1.5 0.2]\n",
            "[1.4 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJvb9WiiPPv"
      },
      "source": [
        "> Mínimos de 1.0 e 0.1 para petal length e petal width respectivamente.\n",
        "\n",
        "> Máximos de 1.9 e 0.6 para petal length e petal width respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlonLxGijIts",
        "outputId": "cc98dcbc-52ed-4fa9-a91f-0c16b408c6aa"
      },
      "source": [
        "Pred_0 = Percep.predict([1.0,0.1])\n",
        "print(Pred_0)\n",
        "Pred_1 = Percep.predict([0.0,0.0])\n",
        "print(Pred_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7NEmm-mjUuW"
      },
      "source": [
        "> Testando o mínimo dos dados de Setosa, pode-se ver que o peceptron reconhece que pétalas pequenas de mais também são Setosas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_d5IZ40hnWi",
        "outputId": "8a32c440-f6b5-41a6-afc7-63f3194a6084"
      },
      "source": [
        "for i in range(150): #Versicolor\n",
        "  if i > 49 and i < 100:\n",
        "    print(X[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.7 1.4]\n",
            "[4.5 1.5]\n",
            "[4.9 1.5]\n",
            "[4.  1.3]\n",
            "[4.6 1.5]\n",
            "[4.5 1.3]\n",
            "[4.7 1.6]\n",
            "[3.3 1. ]\n",
            "[4.6 1.3]\n",
            "[3.9 1.4]\n",
            "[3.5 1. ]\n",
            "[4.2 1.5]\n",
            "[4. 1.]\n",
            "[4.7 1.4]\n",
            "[3.6 1.3]\n",
            "[4.4 1.4]\n",
            "[4.5 1.5]\n",
            "[4.1 1. ]\n",
            "[4.5 1.5]\n",
            "[3.9 1.1]\n",
            "[4.8 1.8]\n",
            "[4.  1.3]\n",
            "[4.9 1.5]\n",
            "[4.7 1.2]\n",
            "[4.3 1.3]\n",
            "[4.4 1.4]\n",
            "[4.8 1.4]\n",
            "[5.  1.7]\n",
            "[4.5 1.5]\n",
            "[3.5 1. ]\n",
            "[3.8 1.1]\n",
            "[3.7 1. ]\n",
            "[3.9 1.2]\n",
            "[5.1 1.6]\n",
            "[4.5 1.5]\n",
            "[4.5 1.6]\n",
            "[4.7 1.5]\n",
            "[4.4 1.3]\n",
            "[4.1 1.3]\n",
            "[4.  1.3]\n",
            "[4.4 1.2]\n",
            "[4.6 1.4]\n",
            "[4.  1.2]\n",
            "[3.3 1. ]\n",
            "[4.2 1.3]\n",
            "[4.2 1.2]\n",
            "[4.2 1.3]\n",
            "[4.3 1.3]\n",
            "[3.  1.1]\n",
            "[4.1 1.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ld3OdnrhwUp"
      },
      "source": [
        "> Mínimos de 3.0 e 1.0 para petal length e petal width respectivamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1QJWC8tfMOH",
        "outputId": "d22d68d7-aea5-492c-b91f-297e5f5189fb"
      },
      "source": [
        "Pred_0 = Percep.predict([2.9,1.0])\n",
        "print(Pred_0)\n",
        "Pred_1 = Percep.predict([3.0,0.9])\n",
        "print(Pred_1)\n",
        "Pred_2 = Percep.predict([3.0,1.0])\n",
        "print(Pred_2)\n",
        "Pred_3 = Percep.predict([2.9,1.1])\n",
        "print(Pred_3)\n",
        "Pred_4 = Percep.predict([3.1,0.9])\n",
        "print(Pred_4)\n",
        "Pred_4 = Percep.predict([3.2,0.9])\n",
        "print(Pred_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86tjD1rKj2Hd"
      },
      "source": [
        "> Testando o mínimo dos dados de Versicolor, pode-se ver que o peceptron reconhece que pétalas muito grandes para serem Setosas também o são."
      ]
    }
  ]
}